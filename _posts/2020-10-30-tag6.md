---
title: "Tag 6 – Metadaten modellieren und Schnittstellen nutzen (1/2)"
date: 2020-10-30
---

*Mit dem Schnellzug durch die Schnittstellen*

## 01 Wo stehen wir im Modul

Nach dem wir in den letzten Vorlesungen verschiedene Systeme und Metadatenstandards kennengelernt haben, versuchen wir heute diese in Verbindung zu bringen bzw. Daten in das gleiche Format zu konvertieren.
Um die Daten aus den 3 Systemen *koha*, *ArchiveSpace* und *DSpace* über die OIA-PMH-Schnittstellen zu sammeln („harvesten / ernten“) brauchen wir das Programm *VuFindHarvest*. 
Aus *koha* kommen die Daten im Format MARC-XML, aus *ArchiveSpace* im Format EAD und aus *DSpace* kommt DublinCore. Diese lassen sich dann dann mit dem Programm *MarcEdit* in MARC21-XML umwandeln. 
Theoretisch könnte *MarcEdit* die Daten über die OIA-PMH-Schnittstellen auch direkt harvesten, aber damit wir verstehen was wo passiert und die Unterschiede der Standards kennenlernen, machen wir die Zwischenschritte manuell.

*VuFindHarvest* ist einer von vielen OAI-Harvestern, die von Bibliothekssystemen wie z.B. Primo eingesetzt werden, um Daten in ihr Discovery-System einzuspielen. 
Die Suchmaschine die bei VuFindHarvest im Hintergrund läuft, heisst Solr. Solr ist eine freie Volltextsuchmaschine, die nicht aus der Bibliotheks- oder Archivwelt kommt, sondern einfach eine Standardanwendung fürs Web ist.

**Erster AHA-Effekt:**
Unterschied zwischen MARC-XML und MARC21-XML - bzw. eben KEIN Unterschied. MARC21 habe ich ja schon im [Blog-Beitrag Tag 2](https://alexmuster.github.io/lerntageblog/2020/09/25/tag2.html) beschrieben. Dabei aber nicht begriffen das MARC (MAchine-Readable Cataloging) ja einfach das ürsprünglich entwickelte Format (von 1966) ist und MARC21 eine der zahlreichen aktuellen Versionen. Auch dachte ich aus irgendeinem Grund das MARC21 sehr aktuell ist, aber das wurde ja schon 1999 erstellt, um zumindest die unterschiedlichen Versionen aus USA und Kanada zu harmonisieren. 



## 02 Schnittstellen / Übertragungsprotokolle

Schnittstellen braucht es um die Daten aus den unterschiedlichen System untereinander auszutauschen - also zu importieren oder zu exportieren. Jede Schnittstelle hat ein Netzwerkprotokoll das Regeln und Formate (Syntax) beinhaltet, die das Verhalten beiden Systeme (Anfang- und Endpunkt) bestimmt. Im Bibliotheks- und Archivbereich sind vorallem diese drei Übertragungsprotokolle weit verbreitet:

#### Z39.50 (Library of Congress)
Z39.50 ist ein Netzwerkprotokoll, das schon etwas älter, aber noch immer oft im Einsatz ist. **Anwendung:** z.B. bei Portalanwendungen wie swissbib oder KVK (ein Zugang zu mehreren bibliographischen Informationssystemen). Oder auch bei Literaturverwaltungsprogrammen wie Citavi verwendet, um die bibliographischen Daten in den Literaturlisten zu ergänzen.

#### SRU - Search/Retrieve via URL (Library of Congress)
Bei den SRU-Schnittstellen geschieht die Suche und das Abfragen in Bibliothekskatalogen via URL, oft als Live-Abfragen.
SRU ist als Weiterentwicklung des Z39.50-Protokolls entstanden - und  basiert auf etablierten Internet-Standards wie URI und XML (die auch über das Bibliothekswesen hinaus im Einsatz sind).

#### OAI-PMH - Open Archives Initiative Protocol for Metadata Harvesting (Open Archives Initiative)
Die OAI-Schnittstelle eignet sich für den Austausch von grösseren Datenmengen und für regelmässige Aktualisierungen. Die Anfrage geschieht ebenso über die URL - über den Browser ohne zusätzliche Software. Voraussetzung für eine regelmässige Synchronisation ist der erstmalige Datenimport eines Grundbestandes in die andere Datenbank. **Anwendung:** z.B. DNB (Deutsche Nationalbibliothek)



## 03 Metadaten über OAI-PMH-Schnittstellen "harvesten"

Harvesting bedeutet soviel wie ernten / einsammeln. Damit ist der Vorgang gemeint, bei dem die Metadaten über eine Schnittstelle von einem Bibliotheks- oder Archivsystem ins andere übertragen werden - sei das jetzt einmalig, in regelmässigen Abständen oder eben live (also ständig).

#### Schritt 1: Sicherstellen der OAI-PMH Endpoints von Koha, ArchivesSpace und DSpace
* Koha haben wir ja installiert und läuft über den Browser (eigene Beispieldaten im System gespeichert im Metadatenformat MarcXML)
* ArchivesSpace muss wieder über das Terminal gestartet werden (eigene Beispieldaten im System gespeichert im Metadatenformat EAD)
* DSpace läuft auch über den Browser, die Demo-Version wird aber jede Samstagnacht gelöscht (deshalb eigene Beispieldaten lokal gespeichert, im Metadatenformat DublinCore)

#### Schritt 2: VuFindHarvest 4.0.1 installieren
VuFind Harvest musste über das Terminal installiert werden mit den vorgegebenen Befehlen und so wurde im Home-Verzeichnis ein Ordner vufindharvest_4.0.1 erstellt.
**Zweiter AHA-Effekt:** Solange ArchiveSpace im Terminal läuft, können da natürlich keine neuen Befehle eingegeben werden. Oben Links gibt es ein +Button, da kann ein neues Fenster geöffnet werden.

#### Schritt 3: Harvesting der Metadaten aus den drei Systemen
Ziel der Übung ist es über eine öffentliche Schnittstellen Beispieldaten in unterschiedlichen Formaten zu harvesten

**Erkenntnisse:** Ich habe die Daten aus ArchivesSpace genommen, im Format EAD. 
Befehle: 

* `cd ~/vufindharvest-4.0.1`
* `php bin/harvest_oai.php --url=http://localhost:8082 --metadataPrefix=oai_ead my_target_dir`

Der Ordner my_target_dir wird automatisch erstellt. Alternativ kann man natürlich selber einen Ordner erstelllen („mkdir“ in der Shell oder traditionell im Ordner Home > vufindharvest_4.0.1)

Als Resultat erhalte ich folgende Files:
- 1604064290_oai_archivesspace__repositories_2_resources_1.xml
- 1604064292_oai_archivesspace__repositories_2_resources_101.xml
- last_harvest.txt 

Die XML-Files sind die einzigen Ressourcen die ich in ArchiveSpace erstellt habe. Und das TXT-File ist das Protokoll wann das letzte Harvesting stattgefunden hat. 

**Repetition Befehle für Shell:**
Ich aber auch die anderen Mitglieder meiner Gruppe nutzen die Shell sonst nie, so hatten wir etwas Mühe bei diesen Schritten. Aber zumindest haben wir gewusst, dass es Befehle gibt für Auflisten, Anzeigen, Ordner erstellen etc. - nur nicht welche. Zeigt sich mal wieder: Können kommt von Machen & Anwenden.

* `ls -a`   list all
* `ls -R`   list all inkl. Unterverzeichnis
* `pwd`    Zeige Link zum Ziel (oder traditionell über Home-Ordner zugreifen)



## 04 XSLT Crosswalks 

Zum Schluss haben wir noch die geharvesteten Daten in ein einheitliches Format (MARC21-XML) konvertiert - über einen sogenannten Crosswalk mit dem Programm MarcEdit.

#### Crosswalks = «Zebrastreifen»
Beschreibt die Konvertierung von einem Metadatenstandard in einen anderen  und beinhaltet Regeln für das Mapping (also wie die Elemente und Werte zugeordnet/verändert/angepasst werden müssen). Im Idealfall ist die Konvertierung verlustfrei, aber meist ist kein 1:1-Zuordnung der Felder möglich, wie wir ja in den Übungen vom letzten Mal bereits gesehen haben.

#### XSLT (XSL-Transformation)
XSLT ist eine Programmiersprache zur Definition von Umwandlungsregeln von XML-Dokumenten und baut auf der Baumstruktur eines XML-Dokuments auf.  
Sie ist Teil der Extensible Stylesheet Language (XSL). 

#### MarcEdit
MarcEdit ist eine kostenlose Software um Metadaten, in erster Linie MARC-Daten, zu bearbeiten. Die Usability ist schon etwas in die Jahre gekommen, aber trotzdem ist es die meistgenutzte Zusatzsoftware für die Arbeit mit MARC. Geharvesteten Daten (z.B. EAD aus ArchiveSpace) können über einen Zusatzschritt in MARC und dann in MARC21-XML umgewandelt werden.








###### Quellen:
###### * https://bain.felixlohmeier.de
###### * https://de.wikipedia.org/wiki/Machine-Readable_Cataloging
###### * https://verbundwiki.gbv.de/display/VZG/Z39.50

